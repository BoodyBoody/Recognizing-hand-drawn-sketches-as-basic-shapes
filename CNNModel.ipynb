{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data = os.listdir('data5')\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root, vfold_ratio=0.2, max_items_per_class= 6000 ):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load each data file \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        if data.shape[0] < max_items_per_class:\n",
    "            continue\n",
    "\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "        \n",
    "        \n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    #randomize the dataset \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    #separate into training and testing \n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data('data5')\n",
    "num_classes = len(class_names)\n",
    "image_size = 28\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \",len(x_train))\n",
    "print(\"Test: \",len(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(int(y_train[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "print(x_train.shape[0])\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(num_classes)\n",
    "print(len(x_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = YOLO(r'YoloComposedColab100\\weights\\best.pt')\n",
    "\n",
    "imgs = []\n",
    "imgsTest = []\n",
    "results = []\n",
    "resultsTest = []\n",
    "for i in range(0,10000):\n",
    "    img = Image.fromarray(np.uint8(x_train[i].reshape((28, 28))*255))\n",
    "    imgs.append(img.resize((256, 256)))\n",
    "    results.append(model.predict(source=img.resize((256, 256)), save=False,  conf=0.25, task='detect')[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000,20000):\n",
    "    img = Image.fromarray(np.uint8(x_train[i].reshape((28, 28))*255))\n",
    "    imgs.append(img.resize((256, 256)))\n",
    "    results.append(model.predict(source=img.resize((256, 256)), save=False,  conf=0.25, task='detect')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000,24000):\n",
    "    img = Image.fromarray(np.uint8(x_train[i].reshape((28, 28))*255))\n",
    "    imgs.append(img.resize((256, 256)))\n",
    "    results.append(model.predict(source=img.resize((256, 256)), save=False,  conf=0.25, task='detect')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_test)):\n",
    "    img = Image.fromarray(np.uint8(x_train[i].reshape((28, 28))*255))\n",
    "    imgsTest.append(img.resize((256, 256)))\n",
    "    resultsTest.append(model.predict(source=img.resize((256, 256)), save=False,  conf=0.25, task='detect')[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" results length: \",len(results), \"\\n\", \"imgs length: \", len(imgs))   \n",
    "print(\" resultsTest length: \",len(resultsTest), \"\\n\", \"imgsTest length: \", len(imgsTest))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "train_data = []\n",
    "    # Set the threshold for object detection\n",
    "conf_threshold = 0.25\n",
    "\n",
    "    # Set the threshold for non-maximum suppression\n",
    "nms_threshold = 0.4\n",
    "\n",
    "\n",
    "for k in range(0,len(imgs)):\n",
    "    # Create a list to store the bounding boxes and class names for the detected objects\n",
    "    boxes = []\n",
    "    class_names2 = []\n",
    "    img = imgs[k]\n",
    "    # Create a new image with the same dimensions as the original image\n",
    "    new_img = np.zeros_like(img)\n",
    "\n",
    "\n",
    "    # Get the bounding boxes and scores\n",
    "    scores = []\n",
    "  \n",
    "\n",
    "    for i in range(len(results[k].boxes.cls)):\n",
    "        scores.append(float(results[k].boxes.cls[i]))\n",
    "\n",
    "    for j in range(len(results[k].boxes.xywh)):\n",
    "        center_x = int(results[k].boxes.xywh[j][0])\n",
    "        center_y = int(results[k].boxes.xywh[j][1])\n",
    "        w = int(results[k].boxes.xywh[j][2])\n",
    "        h = int(results[k].boxes.xywh[j][3])\n",
    "        x = int(center_x - w/2)\n",
    "        y = int(center_y - h/2)\n",
    "        box = [x, y, w, h]\n",
    "        boxes.append(box)\n",
    "        class_names2.append(scores[j])\n",
    "\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    # Loop over the selected boxes\n",
    "    for i in range(0,len(boxes)):\n",
    "        box = boxes[i]\n",
    "        class_name = class_names2[i]\n",
    "        \n",
    "        # Crop the object from the image\n",
    "        crop_img = img.crop((int(box[0]), int(box[1]), int(box[0])+int(box[2]), int(box[1])+int(box[3])))\n",
    "        \n",
    "        # Paste the cropped object onto the new image\n",
    "        new_img.paste(crop_img, (int(box[0]), int(box[1]), int(box[0])+int(box[2]), int(box[1])+int(box[3])))\n",
    "\n",
    "    # Save the new image\n",
    "    if len(results[k].boxes) == 0:\n",
    "        train_data.append(np.asarray(imgs[k]))\n",
    "    else:    \n",
    "        train_data.append(np.asarray(new_img))\n",
    "\n",
    "\n",
    "print(len(train_data))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "test_data = []\n",
    "    # Set the threshold for object detection\n",
    "conf_threshold = 0.25\n",
    "\n",
    "    # Set the threshold for non-maximum suppression\n",
    "nms_threshold = 0.4\n",
    "\n",
    "\n",
    "for k in range(0,len(imgsTest)):\n",
    "    # Create a list to store the bounding boxes and class names for the detected objects\n",
    "    boxes = []\n",
    "    class_names2 = []\n",
    "    # img = cv2.imread('untitled.png')\n",
    "    img = imgsTest[k]\n",
    "    # Create a new image with the same dimensions as the original image\n",
    "    new_img = np.zeros_like(img)\n",
    "\n",
    "\n",
    "    # Get the bounding boxes and scores\n",
    "    scores = []\n",
    "    for i in range(len(resultsTest[k].boxes.cls)):\n",
    "        scores.append(float(resultsTest[k].boxes.cls[i]))\n",
    "\n",
    "    for j in range(len(resultsTest[k].boxes.xywh)):\n",
    "        center_x = int(resultsTest[k].boxes.xywh[j][0])\n",
    "        center_y = int(resultsTest[k].boxes.xywh[j][1])\n",
    "        w = int(resultsTest[k].boxes.xywh[j][2])\n",
    "        h = int(resultsTest[k].boxes.xywh[j][3])\n",
    "        x = int(center_x - w/2)\n",
    "        y = int(center_y - h/2)\n",
    "        box = [x, y, w, h]\n",
    "        boxes.append(box)\n",
    "        class_names2.append(scores[j])\n",
    "\n",
    "    # Apply non-maximum suppression\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    # Loop over the selected boxes\n",
    "    for i in range(0,len(boxes)):\n",
    "        box = boxes[i]\n",
    "        class_name = class_names2[i]\n",
    "        \n",
    "        # Crop the object from the image\n",
    "        crop_img = img.crop((int(box[0]), int(box[1]), int(box[0])+int(box[2]), int(box[1])+int(box[3])))\n",
    "        \n",
    "        # Paste the cropped object onto the new image\n",
    "        new_img.paste(crop_img, (int(box[0]), int(box[1]), int(box[0])+int(box[2]), int(box[1])+int(box[3])))\n",
    "\n",
    "    # Save the new image\n",
    "    if len(results[k].boxes) == 0:\n",
    "        test_data.append(np.asarray(imgs[k]))\n",
    "    else:    \n",
    "        test_data.append(np.asarray(new_img))\n",
    "\n",
    "\n",
    "print(len(test_data))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], 256, 256, 1).astype('float32')\n",
    "test_data = test_data.reshape(test_data.shape[0], 256, 256, 1).astype('float32')\n",
    "\n",
    "train_data /= 255.0\n",
    "test_data /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(train_data))\n",
    "# while int(y_train[idx])!= 2: \n",
    "idx = randint(0, len(train_data))\n",
    "\n",
    "plt.imshow(train_data[idx].reshape(256,256)) \n",
    "print((y_train[idx]))\n",
    "print(\"idx: \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(x = train_data, y = y_train, validation_split=0.1, batch_size = 128, verbose=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ImageAbstractionModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
