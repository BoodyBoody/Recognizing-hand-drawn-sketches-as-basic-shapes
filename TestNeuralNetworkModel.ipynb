{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2   \n",
    "import numpy as np\n",
    "\n",
    "def PrepareImg(img, result):\n",
    "\n",
    "    train_data = []\n",
    "        # Set the threshold for object detection\n",
    "    conf_threshold = 0.25\n",
    "\n",
    "        # Set the threshold for non-maximum suppression\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "        # Create a list to store the bounding boxes and class names for the detected objects\n",
    "    boxes = []\n",
    "    class_names2 = []\n",
    "    # Number of detected shapes\n",
    "    numcircles = 0\n",
    "    numsquares = 0\n",
    "    numlines = 0\n",
    "    numstars = 0\n",
    "    numtriangles = 0\n",
    "    info = [None] * 22\n",
    "\n",
    "    \n",
    "\n",
    "    scores = []\n",
    "\n",
    "\n",
    "    # Get the scores and the number of detected shapes\n",
    "    for i in range(len(result.boxes.cls)):\n",
    "        scores.append(float(result.boxes.cls[i]))\n",
    "        if int(result.boxes.cls[i] == 0):\n",
    "            numcircles +=1\n",
    "        elif int(result.boxes.cls[i] == 1):\n",
    "            numsquares+=1\n",
    "        elif int(result.boxes.cls[i] == 2):\n",
    "            numlines+=1\n",
    "        elif int(result.boxes.cls[i] == 3):\n",
    "            numstars+=1\n",
    "        elif int(result.boxes.cls[i] == 4):  \n",
    "            numtriangles+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    info[0] = numcircles + numsquares + numlines + numstars + numtriangles\n",
    "\n",
    "    info[1] = numcircles\n",
    "    info[2] = numsquares\n",
    "    info[3] = numlines\n",
    "    info[4] = numstars\n",
    "    info[5] = numtriangles\n",
    "    # crop the image into 16 equal regions\n",
    "\n",
    "    width, height = img.size\n",
    "    region_width = width // 4\n",
    "    region_height = height // 4\n",
    "\n",
    "    regions_percentage = []\n",
    "# Loop over the regions and extract each one as a separate image\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "        # Calculate the coordinates of the region\n",
    "            left = j * region_width\n",
    "            upper = i * region_height\n",
    "            right = left + region_width\n",
    "            lower = upper + region_height\n",
    "        \n",
    "            # Crop the image and save it as a separate file\n",
    "            region = img.crop((left, upper, right, lower))\n",
    "            region = np.array(region)\n",
    "\n",
    "            white_pixels = np.sum(region >=127)\n",
    "            per = (white_pixels / 4096)\n",
    "            regions_percentage.append(per)\n",
    "            \n",
    "\n",
    "    for i in range(0,len(regions_percentage)):\n",
    "        info[i+6] = regions_percentage[i]        \n",
    "    \n",
    "\n",
    "    info = np.array(info, dtype=np.float32)\n",
    "    \n",
    "    return info\n",
    "\n",
    " \n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 circles, 139.0ms\n",
      "Speed: 5.0ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "['traffic_light', 'lollipop', 'bicycle', 'laptop', 'house']\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "traffic_light\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "class_names = ['bicycle', 'house' ,'laptop', 'lollipop', 'traffic_light']\n",
    "\n",
    "\n",
    "img = cv2.imread('Untitled.PNG', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "img = cv2.resize(img, (256,256))\n",
    "img = np.array(img)\n",
    "img = img.reshape(-1, 256, 256, 1).astype('float32')\n",
    "img /=255.0\n",
    "imgy = Image.fromarray(np.uint8(img.reshape((256, 256))*255))\n",
    "\n",
    "print(img.shape)\n",
    "Yolo_Model = YOLO(r'YoloComposedColab100\\weights\\best.pt')\n",
    "model = keras.models.load_model(r\"SavedModels\\NNModelArray.h5\")\n",
    "\n",
    "\n",
    "\n",
    "result = Yolo_Model.predict(source=imgy, save=False,  conf=0.25, task='detect')[0]\n",
    "\n",
    "predarr = PrepareImg(imgy, result)\n",
    "\n",
    "predarr = np.array(predarr)\n",
    "predarr = predarr.reshape(1, -1)  # Reshape predarr to a 2D array with a single row\n",
    "\n",
    "prediction = model.predict(predarr)[0]\n",
    "ind = (-prediction).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)\n",
    "\n",
    "\n",
    "prediction = model.predict(predarr)[0]\n",
    "ind = (-prediction).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
